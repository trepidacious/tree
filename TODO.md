# TODO

1. Websocket re-open on close with exponential backoff.
2. If possible, make all deltas directly serialisable - currently we require conversion to JSON inside-out as callback is built from original delta up through parent's deltas. This is messy because we need to retain JSON, we can't reserialise from just the delta. This would be useful for history on server, so we could retain just the deltas for efficiency.
2. Batching of deltas from client to server. Allows for atomic transactions, may be more efficient, and in particular should allow for OT support, since we can guarantee that all deltas are applied as one run on a known server revision.
3. Update client to send delta batches only once per server update, so all batches are specified against a server revision, rather than a server revision + previous local changes. Again this should be compatible with OT a la Wave.
4. Make server store entire history of deltas as applied. See delta serialisation above. This would allow for OT to be applied to batches of deltas from clients, to update them for server deltas applied since their base revision.
6. Add simple incrementing revision for server data model. Allows client delta batches to refer to a base revision, allowing for OT.
7. Add transform method to Delta. This would allow transforming of the delta with another delta. Up until now, we have considered deltas to have the property that they will still attempt to apply when a delta is inserted before them, and will simply do nothing if they are no longer applicable. Consider the case where a client delta A reaches the server after other client's concurrent delta B, so that the data model it operates on is NOT the data model that existed on the client when it was created. In this case we have assumed so far that it is acceptable to just apply A after B on the server, and the delta will be written in such a way that it gives a consistent result. This is essentially the common "optimistic transaction" model, where each delta is a transaction. Since a delta transforms the model and is rerun when applied, it can in many cases have all the logic and data required to apply properly on an updated model. Many deltas fit in this model - for example editing a value (e.g. Int) of an identified object, etc. This often leads to "last write wins" behaviour, which is acceptable for simple values, but may be inadequate for complex ones - the most obvious example is for sequences, e.g. Lists or Strings, where it's difficult for a single delta to know how to apply itself based just on the data model and data within the transaction. For example we might represent inserting a new character in a string as Insert(4, "b"), to insert "b" after the 4th element in the string. In this case we are obviously including the index, 4, as data in the transaction itself based on the intent of the user when operating on a certain revision of the data model. If the data model is then modified by concurrent deltas, inserting or deleting characters before index 4, the insertion of b will not follow the intent of the user. There are techniques to address these, e.g. Logoot will produce an enhanced "index" that can remain valid even when there are concurrent operations, but these tend to have disadvantages in complexity and storage space - in Logoot the indices can grow to unbounded size, in other algorithms the storage can accumulate tombstone markers used to track where deleted items used to be. To avoid this, OT adds logic to deltas so that they can be rearranged within a stream of operations, while preserving the intent of the user. This is done by a transform function that can take a pair of operations that were applied concurrently, and yield a transformed pair of operations that will bring us back to the same data model. This allows for non-commutative operations to be commuted, although all we really need to do is update deltas to account for deltas that were applied before them. The transform method needs to operate on pairs of deltas from an unsealed trait. To do this we need to make the assumption that the deltas exist in sets, where each set will only transform with deltas from the same set, otherwise the transformation simply returns the same pair of operations - i.e. we default to our assumption that concurrent deltas can be run in any order. This is likely to be a good assumption - the sets of mutually transforming deltas will be those that operate on the same data structure within the model. So for example we might have a set of OT deltas for editing Strings, and these will transform against each other when operating on the same String (which will therefore have to be identified, e.g. with a Guid). One complexity is in nested deltas, where we would have to establish whether a "leaf" delta transformation could be used to give a transformation of the parent delta - this is likely to be possible when parents uniquely identify a child, but this may be left to the future - we should probably ensure that deltas implementing ANY transformation are not used with a parent delta, and parent deltas do not implement transform. This would mean that for now, OT deltas would have to operate directly on the data model, which can be neatly achieved by using Mirror/Refs and building the RefParent into the OT delta so we have a single-levelled delta.
8. Add compose method to Delta. This is closely related to transform, in that it operates on pairs of deltas, in sets that will compose with each other. All considerations from transform apply, compose is only different in that it combines a pair of deltas into a single equivalent delta. This can be used to render OT deltas more efficient, by collapsing consecutive deltas on the same data into one delta. Note that this wouldn't combine OT deltas separated by non-OT deltas, since this might not be valid.
9. Add OT logic to client (to batch up deltas and send only one batch to server per server update, based on server revision, with pending deltas being transformed as necessary to account for other clients' deltas received from server) and to server (to further transform received client delta batches to account for deltas from other clients) 
